{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean reverting strategy based on Bollinger bands Strategy\n",
    "\n",
    "This notebook answers question 3.5 form the text book Advances in Financial Machine Learning.\n",
    "\n",
    "3.5 Develop a mean-reverting strategy based on Bollinger bands. For each observation, the model suggests a side, but not a size of the bet.\n",
    "\n",
    "* (a) Derive meta-labels for ptSl = [0, 2] and t1 where numDays = 1. Use as trgt the daily standard deviation as computed by Snippet 3.1.\n",
    "* (b) Train a random forest to decide whether to trade or not. Use as features: volatility, seial correlation, and teh crossinmg moving averages.\n",
    "* (c) What is teh accuracy of prediction from the primary model? (i.e. if the secondary model does not filter the bets) What are the precision, recall and FI-scores?\n",
    "* (d) What is teh accuracy of prediction from the primary model? What are the precision, recall and FI-scores?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Hudson and Thames MlFinLab package\n",
    "import mlfinlab as ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyfolio as pf\n",
    "import timeit\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data\n",
    "We are using the dollar bars based off of the high quality HFT data we purchased. There is a sample of bars available in this branch as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "data = pd.read_csv('../../Sample-Data/dollar_bars.csv')\n",
    "data.index = pd.to_datetime(data['date_time'])\n",
    "data = data.drop('date_time', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute RSI\n",
    "def relative_strength_index(df, n):\n",
    "        \"\"\"Calculate Relative Strength Index(RSI) for given data.\n",
    "        https://github.com/Crypto-toolbox/pandas-technical-indicators/blob/master/technical_indicators.py\n",
    "        \n",
    "        :param df: pandas.DataFrame\n",
    "        :param n: \n",
    "        :return: pandas.DataFrame\n",
    "        \"\"\"\n",
    "        i = 0\n",
    "        UpI = [0]\n",
    "        DoI = [0]\n",
    "        while i + 1 <= df.index[-1]:\n",
    "            UpMove = df.loc[i + 1, 'high'] - df.loc[i, 'high']\n",
    "            DoMove = df.loc[i, 'low'] - df.loc[i + 1, 'low']\n",
    "            if UpMove > DoMove and UpMove > 0:\n",
    "                UpD = UpMove\n",
    "            else:\n",
    "                UpD = 0\n",
    "            UpI.append(UpD)\n",
    "            if DoMove > UpMove and DoMove > 0:\n",
    "                DoD = DoMove\n",
    "            else:\n",
    "                DoD = 0\n",
    "            DoI.append(DoD)\n",
    "            i = i + 1\n",
    "        UpI = pd.Series(UpI)\n",
    "        DoI = pd.Series(DoI)\n",
    "        PosDI = pd.Series(UpI.ewm(span=n, min_periods=n).mean())\n",
    "        NegDI = pd.Series(DoI.ewm(span=n, min_periods=n).mean())\n",
    "        RSI = pd.Series(round(PosDI * 100. / (PosDI + NegDI)), name='RSI_' + str(n))\n",
    "        # df = df.join(RSI)\n",
    "        return RSI\n",
    "\n",
    "def get_rsi(data, window=14):\n",
    "    df = data.copy(deep=True).reset_index()\n",
    "    rsi = relative_strength_index(df, window)\n",
    "    rsi_df = pd.Series(data=rsi.values, index=data.index)\n",
    "    return rsi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbands(close_prices, window, no_of_stdev):\n",
    "    # rolling_mean = close_prices.rolling(window=window).mean()\n",
    "    # rolling_std = close_prices.rolling(window=window).std()\n",
    "    rolling_mean = close_prices.ewm(span=window).mean()\n",
    "    rolling_std = close_prices.ewm(span=window).std()\n",
    "\n",
    "    upper_band = rolling_mean + (rolling_std * no_of_stdev)\n",
    "    lower_band = rolling_mean - (rolling_std * no_of_stdev)\n",
    "\n",
    "    return rolling_mean, upper_band, lower_band"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Fit a Primary Model: Mean-reverting based on Bollinger bands\n",
    "Based on the mean-reverting Bollinger band strategy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute bands\n",
    "window = 50\n",
    "data['avg'], data['upper'], data['lower'] = bbands(data['close'], window, no_of_stdev=1.5)\n",
    "data.sample(10)\n",
    "data.columns.to_series().groupby(data.dtypes).groups #print column types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute RSI\n",
    "rsi_df = get_rsi(data, window=14)\n",
    "data['rsi'] = pd.Series(data=rsi_df.values, index=data.index)\n",
    "\n",
    "# Drop the NaN values from our data set\n",
    "data.dropna(axis=0, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Fit a Primary Model: Bollinger Band Mean-Reversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute sides\n",
    "data['side'] = np.nan \n",
    "\n",
    "long_signals = (data['close'] <= data['lower']) \n",
    "short_signals = (data['close'] >= data['upper']) \n",
    "\n",
    "data.loc[long_signals, 'side'] = 1\n",
    "data.loc[short_signals, 'side'] = -1\n",
    "\n",
    "print(data.side.value_counts())\n",
    "\n",
    "# Remove Look ahead biase by lagging the signal\n",
    "data['side'] = data['side'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the raw data\n",
    "raw_data = data.copy()\n",
    "\n",
    "# Drop the NaN values from our data set\n",
    "data.dropna(axis=0, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.side.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Events: CUSUM Filter\n",
    "Predict what will happen when a CUSUM event is triggered. Use the signal from the MAvg Strategy to determine the side of the bet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute daily volatility\n",
    "daily_vol = ml.util.get_daily_vol(close=data['close'], lookback=50)\n",
    "\n",
    "# Apply Symmetric CUSUM Filter and get timestamps for events\n",
    "# Note: Only the CUSUM filter needs a point estimate for volatility\n",
    "cusum_events = ml.filters.cusum_filter(data['close'], threshold=daily_vol['2011-09-01':'2018-01-01'].mean() * 0.1)\n",
    "\n",
    "# Compute vertical barrier\n",
    "vertical_barriers = ml.labeling.add_vertical_barrier(t_events=cusum_events, close=data['close'], num_days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_date_time_marker(dataframe_to_mark,date_time_index):\n",
    "    bool_array = dataframe_to_mark.index.isin(date_time_index)\n",
    "    print(np.sum(bool_array))# number of markers\n",
    "    extracted_array = dataframe_to_mark[bool_array]\n",
    "    return  extracted_array\n",
    "\n",
    "marker_array = create_date_time_marker(data, cusum_events)\n",
    "\n",
    "def draw_backtest_graph(dataframe,marker_array):\n",
    "    fig, axs = plt.subplots(2,figsize=(30,20))\n",
    "    fig.suptitle('Vertically stacked subplots')\n",
    "\n",
    "    axs[0].plot(dataframe.index, dataframe['close'])\n",
    "    #axs[0].plot(dataframe.index, dataframe['ema'],zorder=6)\n",
    "    axs[0].set_ylabel('Currency')\n",
    "    axs[0].set_xlabel('Time')\n",
    "    axs[0].plot(marker_array.index, marker_array['close'], 'ro', color='r',zorder=10,markersize=10)\n",
    "\n",
    "    ax2 = axs[0].twinx()  # instantiate a second axes that shares the same x-axis\n",
    "    ax2.set_ylabel('sin', color='tab:green')  # we already handled the x-label with ax1\n",
    "    ax2.plot(dataframe.index, dataframe['rsi'], color='tab:green',zorder=5)\n",
    "    ax2.tick_params(axis='y', labelcolor='tab:green')\n",
    "    fig.tight_layout()\n",
    "\n",
    "    axs[1].plot(dataframe.index, dataframe['rsi'])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "draw_backtest_graph(data,marker_array)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_sl = [0, 2]\n",
    "min_ret = 0.0005\n",
    "triple_barrier_events = ml.labeling.get_events(close=data['close'],\n",
    "                                               t_events=cusum_events,\n",
    "                                               pt_sl=pt_sl,\n",
    "                                               target=daily_vol,\n",
    "                                               min_ret=min_ret,\n",
    "                                               num_threads=2,\n",
    "                                               vertical_barrier_times=vertical_barriers,\n",
    "                                               side_prediction=data['side'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ml.labeling.get_bins(triple_barrier_events, data['close'])\n",
    "labels.side.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Results of Primary Model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_forecast = pd.DataFrame(labels['bin'])\n",
    "primary_forecast['pred'] = 1\n",
    "primary_forecast.columns = ['actual', 'pred']\n",
    "\n",
    "# Performance Metrics\n",
    "actual = primary_forecast['actual']\n",
    "pred = primary_forecast['pred']\n",
    "print(classification_report(y_true=actual, y_pred=pred))\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(actual, pred))\n",
    "\n",
    "print('')\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(actual, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A few takeaways**\n",
    "* There is an imbalance in the classes - far more are classified as \"no trade\"\n",
    "* Meta-labeling says that there are many false-positives  \n",
    "* the sklearn's confusion matrix is [[TN, FP][FN, TP]] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Fit a Meta Model\n",
    "Train a random forest to decide whether to trade or not (i.e 1 or 0 respectively) since the earlier model has decided the side (-1 or 1)\n",
    "\n",
    "Create the following features: \n",
    "* Volatility\n",
    "* Serial Correlation\n",
    "* The returns at the different lags from the serial correlation\n",
    "* The sides from the SMavg Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log Returns\n",
    "raw_data['log_ret'] = np.log(raw_data['close']).diff()\n",
    "\n",
    "# Momentum\n",
    "raw_data['mom1'] = raw_data['close'].pct_change(periods=1)\n",
    "raw_data['mom2'] = raw_data['close'].pct_change(periods=2)\n",
    "raw_data['mom3'] = raw_data['close'].pct_change(periods=3)\n",
    "raw_data['mom4'] = raw_data['close'].pct_change(periods=4)\n",
    "raw_data['mom5'] = raw_data['close'].pct_change(periods=5)\n",
    "\n",
    "# Volatility\n",
    "window_stdev = 50\n",
    "raw_data['volatility'] = raw_data['log_ret'].rolling(window=window_stdev, min_periods=window_stdev, center=False).std()\n",
    "\n",
    "# Serial Correlation (Takes about 4 minutes)\n",
    "window_autocorr = 50\n",
    "\n",
    "raw_data['autocorr_1'] = raw_data['log_ret'].rolling(window=window_autocorr, min_periods=window_autocorr, center=False).apply(lambda x: x.autocorr(lag=1), raw=False)\n",
    "raw_data['autocorr_2'] = raw_data['log_ret'].rolling(window=window_autocorr, min_periods=window_autocorr, center=False).apply(lambda x: x.autocorr(lag=2), raw=False)\n",
    "raw_data['autocorr_3'] = raw_data['log_ret'].rolling(window=window_autocorr, min_periods=window_autocorr, center=False).apply(lambda x: x.autocorr(lag=3), raw=False)\n",
    "raw_data['autocorr_4'] = raw_data['log_ret'].rolling(window=window_autocorr, min_periods=window_autocorr, center=False).apply(lambda x: x.autocorr(lag=4), raw=False)\n",
    "raw_data['autocorr_5'] = raw_data['log_ret'].rolling(window=window_autocorr, min_periods=window_autocorr, center=False).apply(lambda x: x.autocorr(lag=5), raw=False)\n",
    "\n",
    "# Get the various log -t returns\n",
    "raw_data['log_t1'] = raw_data['log_ret'].shift(1)\n",
    "raw_data['log_t2'] = raw_data['log_ret'].shift(2)\n",
    "raw_data['log_t3'] = raw_data['log_ret'].shift(3)\n",
    "raw_data['log_t4'] = raw_data['log_ret'].shift(4)\n",
    "raw_data['log_t5'] = raw_data['log_ret'].shift(5)\n",
    "\n",
    "# Add fast and slow moving averages\n",
    "fast_window = 7\n",
    "slow_window = 15\n",
    "\n",
    "raw_data['fast_mavg'] = raw_data['close'].rolling(window=fast_window, min_periods=fast_window, center=False).mean()\n",
    "raw_data['slow_mavg'] = raw_data['close'].rolling(window=slow_window, min_periods=slow_window, center=False).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Trending signals\n",
    "raw_data['sma'] = np.nan\n",
    "\n",
    "long_signals = raw_data['fast_mavg'] >= raw_data['slow_mavg']\n",
    "short_signals = raw_data['fast_mavg'] < raw_data['slow_mavg']\n",
    "raw_data.loc[long_signals, 'sma'] = 1\n",
    "raw_data.loc[short_signals, 'sma'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re compute sides\n",
    "raw_data['side'] = np.nan\n",
    "\n",
    "long_signals = raw_data['close'] <= raw_data['lower'] \n",
    "short_signals = raw_data['close'] >= raw_data['upper'] \n",
    "\n",
    "raw_data.loc[long_signals, 'side'] = 1\n",
    "raw_data.loc[short_signals, 'side'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove look ahead bias\n",
    "raw_data = raw_data.shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#remove missing rows\n",
    "raw_data = raw_data.dropna()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now get the data at the specified events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get features at event dates\n",
    "X = raw_data.loc[labels.index, :]\n",
    "\n",
    "# Drop unwanted columns\n",
    "X.drop(['avg', 'upper', 'lower', 'open', 'high', 'low', 'close', 'cum_vol', 'cum_dollar', 'cum_ticks','fast_mavg', 'slow_mavg',], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "y = labels['bin']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training, validation and test sets\n",
    "X_training_validation = X['2011-09-01':'2018-01-01']\n",
    "y_training_validation = y['2011-09-01':'2018-01-01']\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_training_validation, y_training_validation, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([y_train, X_train], axis=1, join='inner')\n",
    "train_df['bin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsample the training data to have a 50 - 50 split\n",
    "# https://elitedatascience.com/imbalanced-classes\n",
    "majority = train_df[train_df['bin'] == 0]\n",
    "minority = train_df[train_df['bin'] == 1]\n",
    "\n",
    "new_minority = resample(minority, \n",
    "                   replace=True,     # sample with replacement\n",
    "                   n_samples=majority.shape[0],    # to match majority class\n",
    "                   random_state=42)\n",
    "\n",
    "train_df = pd.concat([majority, new_minority])\n",
    "train_df = shuffle(train_df, random_state=42)\n",
    "\n",
    "train_df = train_df.dropna();\n",
    "\n",
    "train_df['bin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training data\n",
    "y_train = train_df['bin']\n",
    "X_train= train_df.loc[:, train_df.columns != 'bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_depth':[2, 3, 4, 5, 7],\n",
    "              'n_estimators':[1, 10, 25, 50, 100, 256, 512],\n",
    "              'random_state':[42]}\n",
    "    \n",
    "def perform_grid_search(X_data, y_data):\n",
    "    rf = RandomForestClassifier(criterion='entropy')\n",
    "    \n",
    "    clf = GridSearchCV(rf, parameters, cv=4, scoring='roc_auc', n_jobs=3)\n",
    "    \n",
    "    clf.fit(X_data, y_data)\n",
    "    \n",
    "    print(clf.cv_results_['mean_test_score'])\n",
    "    \n",
    "    return clf.best_params_['n_estimators'], clf.best_params_['max_depth']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#check for nan values\n",
    "print(np.any(np.isnan(X_train.values))) #false -> required\n",
    "print(np.any(np.isnan(X_validate.values)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# extract parameters\n",
    "n_estimator, depth = perform_grid_search(X_train, y_train)\n",
    "c_random_state = 42\n",
    "print(n_estimator, depth, c_random_state)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Model\n",
    "rf = RandomForestClassifier(max_depth=depth, n_estimators=n_estimator,\n",
    "                            criterion='entropy', random_state=c_random_state)\n",
    "rf.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance Metrics\n",
    "y_pred_rf = rf.predict_proba(X_train)[:, 1]\n",
    "y_pred = rf.predict(X_train)\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_train, y_pred_rf)\n",
    "print(classification_report(y_train, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "\n",
    "print('')\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(y_train, y_pred))\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_rf, tpr_rf, label='RF')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meta-label\n",
    "# Performance Metrics\n",
    "y_pred_rf = rf.predict_proba(X_validate)[:, 1]\n",
    "y_pred = rf.predict(X_validate)\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_validate, y_pred_rf)\n",
    "print(classification_report(y_validate, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_validate, y_pred))\n",
    "\n",
    "print('')\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(y_validate, y_pred))\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_rf, tpr_rf, label='RF')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primary model\n",
    "primary_forecast = pd.DataFrame(labels['bin'])\n",
    "primary_forecast['pred'] = 1\n",
    "primary_forecast.columns = ['actual', 'pred']\n",
    "\n",
    "start = primary_forecast.index.get_loc('2016-08-01 10:31:44.455000')\n",
    "end = primary_forecast.index.get_loc('2016-12-28 19:43:32.240000') + 1\n",
    "\n",
    "subset_prim = primary_forecast[start:end]\n",
    "\n",
    "# Performance Metrics\n",
    "actual = subset_prim['actual']\n",
    "pred = subset_prim['pred']\n",
    "print(classification_report(y_true=actual, y_pred=pred))\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(actual, pred))\n",
    "\n",
    "print('')\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(actual, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "title = 'Feature Importance:'\n",
    "figsize = (15, 5)\n",
    "\n",
    "feat_imp = pd.DataFrame({'Importance':rf.feature_importances_})    \n",
    "feat_imp['feature'] = X.columns\n",
    "feat_imp.sort_values(by='Importance', ascending=False, inplace=True)\n",
    "feat_imp = feat_imp\n",
    "\n",
    "feat_imp.sort_values(by='Importance', inplace=True)\n",
    "feat_imp = feat_imp.set_index('feature', drop=True)\n",
    "feat_imp.plot.barh(title=title, figsize=figsize)\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how low the side is ranked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Performance Tear Sheets (In-sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up the function to extract the KPIs from pyfolio\n",
    "perf_func = pf.timeseries.perf_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daily_returns(intraday_returns):\n",
    "    \"\"\"\n",
    "    This changes returns into daily returns that will work using pyfolio. Its not perfect...\n",
    "    \"\"\"\n",
    "    \n",
    "    cum_rets = ((intraday_returns + 1).cumprod())\n",
    "\n",
    "    # Downsample to daily\n",
    "    daily_rets = cum_rets.resample('B').last()\n",
    "\n",
    "    # Forward fill, Percent Change, Drop NaN\n",
    "    daily_rets = daily_rets.ffill().pct_change().dropna()\n",
    "    \n",
    "    return daily_rets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dates = X_validate.index\n",
    "\n",
    "base_rets = labels.loc[test_dates, 'ret']\n",
    "primary_model_rets = get_daily_returns(base_rets)\n",
    "\n",
    "# Save the statistics in a dataframe\n",
    "perf_stats_all = perf_func(returns=primary_model_rets, \n",
    "                           factor_returns=None, \n",
    "                           positions=None,\n",
    "                           transactions=None,\n",
    "                           turnover_denom=\"AGB\")\n",
    "perf_stats_df = pd.DataFrame(data=perf_stats_all, columns=['Primary Model'])\n",
    "\n",
    "# pf.create_returns_tear_sheet(labels.loc[test_dates, 'ret'], benchmark_rets=None)\n",
    "pf.show_perf_stats(primary_model_rets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_returns = labels.loc[test_dates, 'ret'] * y_pred\n",
    "daily_meta_rets = get_daily_returns(meta_returns)\n",
    "\n",
    "# save the KPIs in a dataframe\n",
    "perf_stats_all = perf_func(returns=daily_meta_rets, \n",
    "                           factor_returns=None, \n",
    "                           positions=None,\n",
    "                           transactions=None,\n",
    "                           turnover_denom=\"AGB\")\n",
    "\n",
    "perf_stats_df['Meta Model'] = perf_stats_all\n",
    "\n",
    "# pf.create_returns_tear_sheet(meta_returns, benchmark_rets=None)\n",
    "pf.show_perf_stats(daily_meta_rets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Perform out-of-sample test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extarct data for out-of-sample (OOS)\n",
    "X_oos = X['2018-01-02':]\n",
    "y_oos = y['2018-01-02':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance Metrics\n",
    "y_pred_rf = rf.predict_proba(X_oos)[:, 1]\n",
    "y_pred = rf.predict(X_oos)\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_oos, y_pred_rf)\n",
    "print(classification_report(y_oos, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_oos, y_pred))\n",
    "\n",
    "print('')\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(y_oos, y_pred))\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_rf, tpr_rf, label='RF')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primary model\n",
    "primary_forecast = pd.DataFrame(labels['bin'])\n",
    "primary_forecast['pred'] = 1\n",
    "primary_forecast.columns = ['actual', 'pred']\n",
    "\n",
    "subset_prim = primary_forecast['2018-01-02':]\n",
    "\n",
    "# Performance Metrics\n",
    "actual = subset_prim['actual']\n",
    "pred = subset_prim['pred']\n",
    "print(classification_report(y_true=actual, y_pred=pred))\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(actual, pred))\n",
    "\n",
    "print('')\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(actual, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Performance Tear Sheets (Out-of-sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dates = X_oos.index\n",
    "\n",
    "base_rets_oos = labels.loc[test_dates, 'ret']\n",
    "primary_model_rets_oos = get_daily_returns(base_rets_oos)\n",
    "\n",
    "# Save the statistics in a dataframe\n",
    "perf_stats_all = perf_func(returns=primary_model_rets_oos, \n",
    "                           factor_returns=None, \n",
    "                           positions=None,\n",
    "                           transactions=None,\n",
    "                           turnover_denom=\"AGB\")\n",
    "\n",
    "perf_stats_df['Primary Model OOS'] = perf_stats_all\n",
    "\n",
    "\n",
    "# pf.create_returns_tear_sheet(labels.loc[test_dates, 'ret'], benchmark_rets=None)\n",
    "pf.show_perf_stats(primary_model_rets_oos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_returns = labels.loc[test_dates, 'ret'] * y_pred\n",
    "daily_rets_meta = get_daily_returns(meta_returns)\n",
    "\n",
    "# save the KPIs in a dataframe\n",
    "perf_stats_all = perf_func(returns=daily_rets_meta, \n",
    "                           factor_returns=None, \n",
    "                           positions=None,\n",
    "                           transactions=None,\n",
    "                           turnover_denom=\"AGB\")\n",
    "\n",
    "perf_stats_df['Meta Model OOS'] = perf_stats_all\n",
    "\n",
    "pf.create_returns_tear_sheet(daily_rets_meta, benchmark_rets=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Conclusion\n",
    "There are a few takeaways from the Bollinger bands mean-reverting strategy:\n",
    "1. In out-of-sample tests, the meta-model out-performs the primary model in all key statistics:\n",
    "    * Annualized returns: 17.7% vs. 35.3%\n",
    "    * Annualized volatility: 95% vs. 40%\n",
    "    * Sharpe ratio: 0.65 vs. 0.82 \n",
    "2. In all cases the meta-model (one with meta-labeling) decreases annualized volatility, maximum drawdown and increases Sharpe ratio compared to the primary model     \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-bf98ad8e",
   "language": "python",
   "display_name": "PyCharm (trading-strategies)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}